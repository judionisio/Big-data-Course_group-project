{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------+-----------+-----------+--------+-----------+-----------+--------+\n",
      "|g_confirmed|g_recovered|g_deaths|c_confirmed|c_recovered|c_deaths|o_confirmed|o_recovered|o_deaths|\n",
      "+-----------+-----------+--------+-----------+-----------+--------+-----------+-----------+--------+\n",
      "|      555.0|       28.0|    17.0|        0.0|        0.0|     0.0|        0.0|        0.0|     0.0|\n",
      "|      654.0|       30.0|    18.0|        0.0|        0.0|     0.0|        0.0|        0.0|     0.0|\n",
      "|      941.0|       36.0|    26.0|        0.0|        0.0|     0.0|        0.0|        0.0|     0.0|\n",
      "|     1434.0|       39.0|    42.0|        0.0|        0.0|     0.0|        0.0|        0.0|     0.0|\n",
      "|     2118.0|       52.0|    56.0|        1.0|        0.0|     0.0|        1.0|        0.0|     0.0|\n",
      "|     2927.0|       61.0|    82.0|        1.0|        0.0|     0.0|        1.0|        0.0|     0.0|\n",
      "|     5578.0|      107.0|   131.0|        2.0|        0.0|     0.0|        1.0|        0.0|     0.0|\n",
      "|     6166.0|      126.0|   133.0|        2.0|        0.0|     0.0|        1.0|        0.0|     0.0|\n",
      "|     8234.0|      143.0|   171.0|        2.0|        0.0|     0.0|        1.0|        0.0|     0.0|\n",
      "|     9927.0|      222.0|   213.0|        4.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    12038.0|      284.0|   259.0|        4.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    16787.0|      472.0|   362.0|        4.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    19881.0|      623.0|   426.0|        4.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    23892.0|      852.0|   492.0|        4.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    27635.0|     1124.0|   564.0|        5.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    30794.0|     1487.0|   634.0|        5.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    34391.0|     2011.0|   719.0|        7.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    37120.0|     2616.0|   806.0|        7.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    40150.0|     3244.0|   906.0|        7.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "|    42762.0|     3946.0|  1013.0|        7.0|        0.0|     0.0|        3.0|        0.0|     0.0|\n",
      "+-----------+-----------+--------+-----------+-----------+--------+-----------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Ops').getOrCreate()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Confirmed\n",
    "c_df = pd.read_csv(\"time_series_covid19_confirmed_global.csv\")\n",
    "global_c_total = c_df.select_dtypes(pd.np.number).sum().to_frame()\n",
    "canada_c_total = c_df[c_df['Country/Region'] == 'Canada'].select_dtypes(pd.np.number).sum().to_frame()\n",
    "ontario_c_total = c_df[c_df['Province/State'] == 'Ontario'].select_dtypes(pd.np.number).sum().to_frame()\n",
    "\n",
    "# Recovered\n",
    "r_df = pd.read_csv(\"time_series_covid19_recovered_global.csv\")\n",
    "global_r_total = r_df.select_dtypes(pd.np.number).sum().to_frame()\n",
    "canada_r_total = r_df[r_df['Country/Region'] == 'Canada'].select_dtypes(pd.np.number).sum().to_frame()\n",
    "ontario_r_total = r_df[r_df['Province/State'] == 'Ontario'].select_dtypes(pd.np.number).sum().to_frame()\n",
    "\n",
    "# Deaths\n",
    "d_df = pd.read_csv(\"time_series_covid19_deaths_global.csv\")\n",
    "global_d_total = d_df.select_dtypes(pd.np.number).sum().to_frame()\n",
    "canada_d_total = d_df[d_df['Country/Region'] == 'Canada'].select_dtypes(pd.np.number).sum().to_frame()\n",
    "ontario_d_total = d_df[d_df['Province/State'] == 'Ontario'].select_dtypes(pd.np.number).sum().to_frame()\n",
    "\n",
    "# Merging Global Dataset\n",
    "global_df = pd.concat([global_c_total, global_r_total, global_d_total], axis=1)\n",
    "global_df.columns = ['g_confirmed','g_recovered','g_deaths']\n",
    "global_df = global_df.drop(['Lat','Long'], axis=0)\n",
    "\n",
    "# Merging Canada Dataset\n",
    "canada_df = pd.concat([canada_c_total, canada_r_total, canada_d_total], axis=1)\n",
    "canada_df.columns = ['c_confirmed','c_recovered','c_deaths']\n",
    "canada_df = canada_df.drop(['Lat','Long'], axis=0)\n",
    "\n",
    "# Merging Ontario Dataset\n",
    "ontario_df = pd.concat([ontario_c_total, ontario_r_total, ontario_d_total], axis=1)\n",
    "ontario_df.columns = ['o_confirmed','o_recovered','o_deaths']\n",
    "ontario_df = ontario_df.drop(['Lat','Long'], axis=0)\n",
    "\n",
    "# Merging all dataset\n",
    "df = pd.concat([global_df,canada_df,ontario_df], axis=1)\n",
    "df = spark.createDataFrame(df)\n",
    "df.toPandas().to_csv('Spark_df.csv')\n",
    "df.show()\n",
    "\n",
    "#c_df = spark.read.csv(\"time_series_covid19_confirmed_global.csv\", header=True)\n",
    "#d_df = spark.read.csv(\"time_series_covid19_deaths_global.csv\", header=True)\n",
    "#r_df = spark.read.csv(\"time_series_covid19_recovered_global.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0001, 0.0001, -0.0026, 0.0016, -0.0067, 0.7166, 0.0058, 0.0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\"g_confirmed\",\"g_recovered\",\"g_deaths\",\n",
    "               \"c_confirmed\",\"c_recovered\",\"c_deaths\",\n",
    "               \"o_confirmed\",\"o_recovered\"], outputCol=\"features\")\n",
    "\"\"\"\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\"g_confirmed\",\"g_deaths\",\n",
    "               \"c_confirmed\",\"c_deaths\",\n",
    "               \"o_confirmed\"], outputCol=\"features\")\n",
    "\"\"\"\n",
    "\n",
    "df = vectorAssembler.transform(df)\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"o_deaths\")\n",
    "lr_model = lr.fit(df)\n",
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16802774778269086"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810006656488205"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4591907302238774"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "splits = df.randomSplit([0.7,0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"o_deaths\")\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(labelCol=\"o_deaths\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4591907302238774"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"o_deaths\")\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_evaluator = RegressionEvaluator(labelCol=\"o_deaths\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "gbt_rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "gbt_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
